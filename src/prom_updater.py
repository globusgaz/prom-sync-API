# src/prom_updater.py
import os
import asyncio
import aiohttp
import lxml.etree as ET
from dotenv import load_dotenv
import orjson

load_dotenv()

PROM_API_TOKEN = os.getenv("PROM_API_TOKEN")
PROM_EDIT_URL = "https://my.prom.ua/api/v1/products/edit"

HEADERS = {
    "Authorization": f"Bearer {PROM_API_TOKEN}",
    "Content-Type": "application/json",
}

BATCH_SIZE = 100      # —Å–∫—ñ–ª—å–∫–∏ —Ç–æ–≤–∞—Ä—ñ–≤ —É –∑–∞–ø–∏—Ç—ñ
MAX_CONCURRENT = 5    # –ø–∞—Ä–∞–ª–µ–ª—å–Ω—ñ –∑'—î–¥–Ω–∞–Ω–Ω—è


# ==== –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ—ñ–¥—ñ–≤ ====
async def fetch_feed(session, url: str):
    try:
        async with session.get(url, headers={"User-Agent": "Mozilla/5.0"}) as resp:
            resp.raise_for_status()
            text = await resp.text()
            root = ET.fromstring(text.encode("utf-8"))
            offers = root.findall(".//offer")
            print(f"‚úÖ {url} ‚Äî {len(offers)} —Ç–æ–≤–∞—Ä—ñ–≤")
            return offers
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É {url}: {e}")
        return []


async def load_all_feeds(file_path="feeds.txt"):
    with open(file_path, "r") as f:
        urls = [line.strip() for line in f if line.strip()]

    async with aiohttp.ClientSession() as session:
        tasks = [fetch_feed(session, url) for url in urls]
        results = await asyncio.gather(*tasks)
        return [offer for sublist in results for offer in sublist]


# ==== –í—ñ–¥–ø—Ä–∞–≤–∫–∞ –±–∞—Ç—á—ñ–≤ ====
async def send_batch(session, batch):
    try:
        payload = {"products": batch}
        async with session.post(PROM_EDIT_URL, headers=HEADERS, data=orjson.dumps(payload)) as resp:
            text = await resp.text()
            if resp.status != 200:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ Prom {resp.status}: {text}")
            else:
                print(f"‚úÖ Batch {len(batch)} ‚Äî OK")
    except Exception as e:
        print(f"‚ö†Ô∏è –í–∏–Ω—è—Ç–æ–∫ –ø—Ä–∏ –≤—ñ–¥–ø—Ä–∞–≤—Ü—ñ batch: {e}")


async def update_products(updates):
    if not updates:
        print("üö´ –ù–µ–º–∞—î –æ–Ω–æ–≤–ª–µ–Ω—å")
        return

    batches = [updates[i:i + BATCH_SIZE] for i in range(0, len(updates), BATCH_SIZE)]

    connector = aiohttp.TCPConnector(limit=MAX_CONCURRENT)
    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = [send_batch(session, batch) for batch in batches]
        await asyncio.gather(*tasks)


# ==== –ì–æ–ª–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ ====
async def main():
    offers = await load_all_feeds()
    print(f"üì¶ –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤: {len(offers)}")

    updates = []
    for offer in offers:
        external_id = offer.get("id") or offer.findtext("vendorCode")
        price = offer.findtext("price")
        quantity = offer.findtext("quantity")

        if external_id and price:
            qty = int(quantity) if quantity else 0
            presence = "available" if qty > 0 else "not_available"

            updates.append(
                {
                    "external_id": external_id,
                    "price": float(price),
                    "quantity_in_stock": qty,
                    "presence": presence,
                }
            )

    print(f"üõ†Ô∏è –ì–æ—Ç–æ–≤–æ {len(updates)} –æ–Ω–æ–≤–ª–µ–Ω—å")
    await update_products(updates)


if __name__ == "__main__":
    asyncio.run(main())
